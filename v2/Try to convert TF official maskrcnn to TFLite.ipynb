{"cells":[{"cell_type":"markdown","metadata":{"id":"YrT1XbjWQLhW"},"source":["# Try to convert TF official maskrcnn to TFLite\n","\n","Let's try to follow the TFLite Exercise to convert our baseline so we can try to deploy it on ElasticBeanStalk with Flask."]},{"cell_type":"markdown","metadata":{"id":"bL54LWCHt5q5"},"source":["## 1. Pull and build the full model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPEmmeZdd7iB","executionInfo":{"status":"ok","timestamp":1651618704394,"user_tz":420,"elapsed":3450,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"20e3351c-2e6c-4b7b-e973-1ac31850b219"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version:  2.8.0\n","Eager mode:  True\n","Hub version:  0.12.0\n"]},{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{},"execution_count":3}],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print(\"Tensorflow version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"Hub version: \", hub.__version__)\n","tf.config.list_physical_devices('GPU')"]},{"cell_type":"markdown","source":["### Clone the official models repo and install object_detection"],"metadata":{"id":"AzxU6sD430dl"}},{"cell_type":"code","source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kS4BhQEk3pXb","executionInfo":{"status":"ok","timestamp":1651618727697,"user_tz":420,"elapsed":4141,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"9959790e-abfa-404c-a28a-8e3c9df07ae1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 3335, done.\u001b[K\n","remote: Counting objects: 100% (3335/3335), done.\u001b[K\n","remote: Compressing objects: 100% (2763/2763), done.\u001b[K\n","remote: Total 3335 (delta 885), reused 1379 (delta 522), pack-reused 0\u001b[K\n","Receiving objects: 100% (3335/3335), 34.32 MiB | 24.00 MiB/s, done.\n","Resolving deltas: 100% (885/885), done.\n"]}]},{"cell_type":"code","source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cW6ouYS03v__","executionInfo":{"status":"ok","timestamp":1651618775580,"user_tz":420,"elapsed":39775,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"fa668751-1fde-4643-e1ba-692612f8eae6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.38.0-cp37-cp37m-manylinux2010_x86_64.whl (10.2 MB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","Collecting tensorflow_io\n","  Downloading tensorflow_io-0.25.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","Collecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.25.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","Collecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.4.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1692480 sha256=f81dc5c44f96a3271123fb6960dc394ff1d5e0e2add6dcd310aeef5ef32ae2ac\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-j40gxxi7/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py): started\n","  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=5cae18df870166ef15ad40004a7af68b329ed86528585913a405bdc8f8b64eb4\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=07e720bff5ff017ee56ba4d148a16d633187260d9db2d9a3b1e6779babe700ad\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=09438966594cc9ed4e390369a8ff4bd7b319c7163d0ea8062207d117acfa1257\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=c161681ca90000d7ab94d68085c6da1fadfa7fad66437e4b212c44d4baddb2c5\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.1.1\n","    Uninstalling pymongo-4.1.1:\n","      Successfully uninstalled pymongo-4.1.1\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","Successfully installed apache-beam-2.38.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.11 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.1 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.25.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"]},{"output_type":"stream","name":"stderr","text":["  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"]}]},{"cell_type":"markdown","source":["### Download and set up the model"],"metadata":{"id":"ge968xIu7vLx"}},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"metadata":{"id":"n-rglSai4QN_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl -O http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdkMo2g-4T2Y","executionInfo":{"status":"ok","timestamp":1651618794724,"user_tz":420,"elapsed":3200,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"3a7867da-3d0c-479c-cd47-712cefa3979d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  462M  100  462M    0     0   162M      0  0:00:02  0:00:02 --:--:--  162M\n"]}]},{"cell_type":"code","source":["!tar zxvf mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OumsN5hG5kjo","executionInfo":{"status":"ok","timestamp":1651618804380,"user_tz":420,"elapsed":6417,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"1c6301c1-43bc-45e6-a1ae-0a47ff1e8690"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/checkpoint\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.index\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/saved_model.pb\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets/\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.data-00000-of-00001\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"code","source":["!cp -rp mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint models/research/object_detection/test_data"],"metadata":{"id":"i9CP7qc07TMY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Get ready for inference"],"metadata":{"id":"LhH4-CmR8AJu"}},{"cell_type":"code","source":["model_name = 'mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8'\n","pipeline_config = os.path.join('models/research/object_detection/configs/tf2/',\n","                                model_name + '.config')\n","model_dir = 'models/research/object_detection/test_data/checkpoint/'\n","\n","# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","detection_model = model_builder.build(\n","      model_config=model_config, is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n","\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)"],"metadata":{"id":"qfFTKBTc6la-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Run inference to make sure it works"],"metadata":{"id":"kovI7YGF8N7b"}},{"cell_type":"markdown","source":["### Download a test image"],"metadata":{"id":"pkIBmVSS8S_c"}},{"cell_type":"code","source":["!curl -O https://raw.githubusercontent.com/CSAILVision/ADE20K/main/dataset/ADE20K_2021_17_01/images/ADE/training/urban/street/ADE_train_00016869.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88L_Zw8a7o70","executionInfo":{"status":"ok","timestamp":1651615133100,"user_tz":420,"elapsed":574,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"f32bbb12-3b84-48e5-af37-5668f4920c7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 1079k  100 1079k    0     0  3646k      0 --:--:-- --:--:-- --:--:-- 3646k\n"]}]},{"cell_type":"markdown","source":["### Prepare class labels"],"metadata":{"id":"UJpePSPN8VxI"}},{"cell_type":"code","source":["# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"metadata":{"id":"9EJv8rJS8LDv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load model and run inference"],"metadata":{"id":"Cku5KrGh8dmq"}},{"cell_type":"code","source":["!find mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_2632W69nY2","executionInfo":{"status":"ok","timestamp":1651618828694,"user_tz":420,"elapsed":200,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"3ca60dee-a807-4908-b9b3-b7bb617520da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.data-00000-of-00001\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.index\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/saved_model.pb\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/checkpoint\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.index\n","mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n"]}]},{"cell_type":"code","source":["model_dir = pathlib.Path('mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8')/\"saved_model\"\n","model = tf.saved_model.load(str(model_dir))"],"metadata":{"id":"KBD4wWSs9Np1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["segment_fn = get_model_detection_function(model)"],"metadata":{"id":"byHRx4oW_Huw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path = 'ADE_train_00016869.jpg'\n","\n","# the array based representation of the image will be used later in order to prepare the\n","# result image with boxes and labels on it.\n","image_np = np.array(Image.open(image_path))\n","\n","# Actual detection.\n","# input_tensor = tf.convert_to_tensor(\n","#     np.expand_dims(image_np, 0), dtype=tf.float32)\n","# detections, predictions_dict, shapes = detect_fn(input_tensor)\n","\n","# output_dict = run_inference_for_single_image(model, image_np)"],"metadata":{"id":"_QGV70zi7zGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","input_tensor = tf.convert_to_tensor(image_np)\n","# The model expects a batch of images, so add an axis with `tf.newaxis`.\n","input_tensor = input_tensor[tf.newaxis,...]\n","\n","# Run inference\n","model_fn = model.signatures['serving_default']\n","output_dict = model_fn(input_tensor)"],"metadata":{"id":"5Bv8QyStAell"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Examine results"],"metadata":{"id":"oi4eEo6I8kdk"}},{"cell_type":"code","source":["for k in output_dict.keys():\n","  print(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0hqEKFoAvqd","executionInfo":{"status":"ok","timestamp":1651617575913,"user_tz":420,"elapsed":188,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"a6b34c42-91ef-45d9-d77a-e257dc564e4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["class_predictions_with_background\n","proposal_boxes_normalized\n","mask_predictions\n","final_anchors\n","raw_detection_scores\n","rpn_box_predictor_features\n","refined_box_encodings\n","detection_scores\n","rpn_objectness_predictions_with_background\n","raw_detection_boxes\n","detection_multiclass_scores\n","rpn_box_encodings\n","num_detections\n","detection_masks\n","detection_boxes\n","box_classifier_features\n","rpn_features_to_crop\n","detection_classes\n","proposal_boxes\n","detection_anchor_indices\n","anchors\n","image_shape\n","num_proposals\n"]}]},{"cell_type":"code","source":["num_detections = int(output_dict['num_detections'])\n","predictions = {}\n","predictions['num_detections'] = num_detections\n","for k in ['boxes', 'classes', 'masks', 'scores']:\n","  key = 'detection_{}'.format(k)\n","  predictions[key] = output_dict[key][0, :num_detections].numpy()\n","\n","predictions['detection_classes'] = predictions['detection_classes'].astype(np.int64)\n","\n","if 'detection_masks' in output_dict:\n","  # Reframe the the bbox mask to the image size.\n","  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","    predictions['detection_masks'],\n","    predictions['detection_boxes'],\n","    image_np.shape[0],\n","    image_np.shape[1]\n","  )\n","  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n","  predictions['detection_masks_reframed'] = detection_masks_reframed.numpy()"],"metadata":{"id":"dkDOatl7CWPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualization of the results of a detection.\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","    image_np,\n","    predictions['detection_boxes'],\n","    predictions['detection_classes'],\n","    predictions['detection_scores'],\n","    category_index,\n","    instance_masks=predictions.get('detection_masks_reframed', None),\n","    use_normalized_coordinates=True,\n","    line_thickness=8)\n","\n","display(Image.fromarray(image_np))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Ikmj5Tj-Vz0QqFnkFYngDIjFWSCtMH7V"},"id":"OUZRaeqKAjrq","executionInfo":{"status":"ok","timestamp":1651617770657,"user_tz":420,"elapsed":9296,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"0a9d2ba1-f615-435d-9c2e-2f2a415e4e9b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## 3. Save the model and load it back up\n","\n","I tried converting directly from step 1 above but it didn't work. Could this work, possibly? This is just like the TFLite Exercise. First we save the model, and then we load it, and then we convert to TFLite."],"metadata":{"id":"WBIdaJUG8pCw"}},{"cell_type":"code","source":["model_save_path = './'\n","full_model_save_path = './saved_model'"],"metadata":{"id":"M77tWfvFH5qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.saved_model.save(\n","  obj=model,\n","  export_dir=full_model_save_path\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IShuKIGIKhx","executionInfo":{"status":"ok","timestamp":1651619126897,"user_tz":420,"elapsed":28292,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"747b73a9-609a-4d76-88a3-e107fb65da09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 50). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ./saved_model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: ./saved_model/assets\n"]}]},{"cell_type":"code","source":["%%bash -s \"$full_model_save_path\"\n","saved_model_cli show --dir \"$1\" --tag_set serve --signature_def serving_default"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8DP2jXkIiFi","executionInfo":{"status":"ok","timestamp":1651619146783,"user_tz":420,"elapsed":4020,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"9cae2ebb-a044-4200-821b-d3ca7c0b61e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The given SavedModel SignatureDef contains the following input(s):\n","  inputs['input_tensor'] tensor_info:\n","      dtype: DT_UINT8\n","      shape: (1, -1, -1, 3)\n","      name: serving_default_input_tensor:0\n","The given SavedModel SignatureDef contains the following output(s):\n","  outputs['anchors'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (-1, 4)\n","      name: StatefulPartitionedCall:0\n","  outputs['box_classifier_features'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (300, 9, 9, 1536)\n","      name: StatefulPartitionedCall:1\n","  outputs['class_predictions_with_background'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (300, 91)\n","      name: StatefulPartitionedCall:2\n","  outputs['detection_anchor_indices'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 100)\n","      name: StatefulPartitionedCall:3\n","  outputs['detection_boxes'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 100, 4)\n","      name: StatefulPartitionedCall:4\n","  outputs['detection_classes'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 100)\n","      name: StatefulPartitionedCall:5\n","  outputs['detection_masks'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 100, 33, 33)\n","      name: StatefulPartitionedCall:6\n","  outputs['detection_multiclass_scores'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 100, 91)\n","      name: StatefulPartitionedCall:7\n","  outputs['detection_scores'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 100)\n","      name: StatefulPartitionedCall:8\n","  outputs['final_anchors'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 300, 4)\n","      name: StatefulPartitionedCall:9\n","  outputs['image_shape'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (4)\n","      name: StatefulPartitionedCall:10\n","  outputs['mask_predictions'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (100, 90, 33, 33)\n","      name: StatefulPartitionedCall:11\n","  outputs['num_detections'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1)\n","      name: StatefulPartitionedCall:12\n","  outputs['num_proposals'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1)\n","      name: StatefulPartitionedCall:13\n","  outputs['proposal_boxes'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 300, 4)\n","      name: StatefulPartitionedCall:14\n","  outputs['proposal_boxes_normalized'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 300, 4)\n","      name: StatefulPartitionedCall:15\n","  outputs['raw_detection_boxes'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 300, 4)\n","      name: StatefulPartitionedCall:16\n","  outputs['raw_detection_scores'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 300, 91)\n","      name: StatefulPartitionedCall:17\n","  outputs['refined_box_encodings'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (300, 90, 4)\n","      name: StatefulPartitionedCall:18\n","  outputs['rpn_box_encodings'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 49152, 4)\n","      name: StatefulPartitionedCall:19\n","  outputs['rpn_box_predictor_features'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 64, 64, 512)\n","      name: StatefulPartitionedCall:20\n","  outputs['rpn_features_to_crop'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 64, 64, 1088)\n","      name: StatefulPartitionedCall:21\n","  outputs['rpn_objectness_predictions_with_background'] tensor_info:\n","      dtype: DT_FLOAT\n","      shape: (1, 49152, 2)\n","      name: StatefulPartitionedCall:22\n","Method name is: tensorflow/serving/predict\n"]}]},{"cell_type":"code","source":["loaded = tf.saved_model.load(export_dir=full_model_save_path) # [YOUR CODE HERE]\n","\n","print(list(loaded.signatures.keys()))\n","infer = loaded.signatures[\"serving_default\"]\n","print(infer.structured_input_signature)\n","print(infer.structured_outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17YgFOLtIqkA","executionInfo":{"status":"ok","timestamp":1651619340893,"user_tz":420,"elapsed":42235,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"ee2b429b-efac-4f38-f941-68447d319362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['serving_default']\n","((), {'input_tensor': TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name='input_tensor')})\n","{'detection_boxes': TensorSpec(shape=(1, 100, 4), dtype=tf.float32, name='detection_boxes'), 'detection_masks': TensorSpec(shape=(1, 100, 33, 33), dtype=tf.float32, name='detection_masks'), 'anchors': TensorSpec(shape=(None, 4), dtype=tf.float32, name='anchors'), 'detection_anchor_indices': TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_anchor_indices'), 'rpn_box_encodings': TensorSpec(shape=(1, 49152, 4), dtype=tf.float32, name='rpn_box_encodings'), 'box_classifier_features': TensorSpec(shape=(300, 9, 9, 1536), dtype=tf.float32, name='box_classifier_features'), 'image_shape': TensorSpec(shape=(4,), dtype=tf.float32, name='image_shape'), 'detection_scores': TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_scores'), 'detection_classes': TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_classes'), 'rpn_box_predictor_features': TensorSpec(shape=(1, 64, 64, 512), dtype=tf.float32, name='rpn_box_predictor_features'), 'proposal_boxes_normalized': TensorSpec(shape=(1, 300, 4), dtype=tf.float32, name='proposal_boxes_normalized'), 'final_anchors': TensorSpec(shape=(1, 300, 4), dtype=tf.float32, name='final_anchors'), 'num_detections': TensorSpec(shape=(1,), dtype=tf.float32, name='num_detections'), 'proposal_boxes': TensorSpec(shape=(1, 300, 4), dtype=tf.float32, name='proposal_boxes'), 'mask_predictions': TensorSpec(shape=(100, 90, 33, 33), dtype=tf.float32, name='mask_predictions'), 'raw_detection_scores': TensorSpec(shape=(1, 300, 91), dtype=tf.float32, name='raw_detection_scores'), 'class_predictions_with_background': TensorSpec(shape=(300, 91), dtype=tf.float32, name='class_predictions_with_background'), 'num_proposals': TensorSpec(shape=(1,), dtype=tf.float32, name='num_proposals'), 'detection_multiclass_scores': TensorSpec(shape=(1, 100, 91), dtype=tf.float32, name='detection_multiclass_scores'), 'refined_box_encodings': TensorSpec(shape=(300, 90, 4), dtype=tf.float32, name='refined_box_encodings'), 'rpn_features_to_crop': TensorSpec(shape=(1, 64, 64, 1088), dtype=tf.float32, name='rpn_features_to_crop'), 'rpn_objectness_predictions_with_background': TensorSpec(shape=(1, 49152, 2), dtype=tf.float32, name='rpn_objectness_predictions_with_background'), 'raw_detection_boxes': TensorSpec(shape=(1, 300, 4), dtype=tf.float32, name='raw_detection_boxes')}\n"]}]},{"cell_type":"markdown","source":["## 4. Convert to TFLite"],"metadata":{"id":"zehAPx9s9MJz"}},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=full_model_save_path) # [YOUR CODE HERE]\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]"],"metadata":{"id":"cNGra5vK_fM1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tflite_model_save_path = \"./maskrcnn.tflite\"\n","tflite_model = converter.convert()\n","with open(tflite_model_save_path, \"wb\") as f:\n","    # [YOUR CODE HERE]\n","    f.write(tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Gl9l_vEm_dpD","executionInfo":{"status":"error","timestamp":1651619420147,"user_tz":420,"elapsed":20911,"user":{"displayName":"Juswaldy Jusman","userId":"04395087425696224653"}},"outputId":"acaaf2ac-26a4-4544-b3c7-4e4a5a58fd30"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ConverterError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-9dc9504be879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtflite_model_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./maskrcnn.tflite\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# [YOUR CODE HERE]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1082\u001b[0m           graph_def)\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_from_saved_model\u001b[0;34m(self, graph_def)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m     return self._optimize_tflite_model(\n\u001b[1;32m    969\u001b[0m         result, quant_mode, quant_io=self.experimental_new_quantizer)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_saved_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m       \u001b[0minput_data_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m       enable_mlir_converter=True)\n\u001b[0m\u001b[1;32m    795\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags_str, conversion_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0merror_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_metrics_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_collected_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m   return _run_deprecated_conversion_binary(\n","\u001b[0;31mConverterError\u001b[0m: <unknown>:0: error: loc(callsite(callsite(callsite(fused[\"CropAndResize:\", \"CropAndResize/CropAndResize\", \"CropAndResize/CropAndResize@__inference___call___42606\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_restored_function_body_104618\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_106911\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): 'tf.CropAndResize' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: note: loc(callsite(callsite(callsite(fused[\"CropAndResize:\", \"CropAndResize/CropAndResize\", \"CropAndResize/CropAndResize@__inference___call___42606\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_restored_function_body_104618\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_106911\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(callsite(fused[\"CropAndResize:\", \"CropAndResize_1/CropAndResize\", \"CropAndResize_1/CropAndResize@__inference___call___42606\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_restored_function_body_104618\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_106911\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): 'tf.CropAndResize' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: note: loc(callsite(callsite(callsite(fused[\"CropAndResize:\", \"CropAndResize_1/CropAndResize\", \"CropAndResize_1/CropAndResize@__inference___call___42606\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_restored_function_body_104618\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_106911\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: CropAndResize\nDetails:\n\ttf.CropAndResize(tensor<1x64x64x1088xf32>, tensor<?x4xf32>, tensor<100xi32>, tensor<2xi32>) -> (tensor<100x17x17x1088xf32>) : {T = f32, device = \"\", extrapolation_value = 0.000000e+00 : f32, method = \"bilinear\"}\n\ttf.CropAndResize(tensor<1x64x64x1088xf32>, tensor<?x4xf32>, tensor<300xi32>, tensor<2xi32>) -> (tensor<300x17x17x1088xf32>) : {T = f32, device = \"\", extrapolation_value = 0.000000e+00 : f32, method = \"bilinear\"}\n\n"]}]},{"cell_type":"markdown","metadata":{"id":"mmaHHH7Pvmth"},"source":["Fail!"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Try to convert TF official maskrcnn to TFLite.ipynb","provenance":[],"machine_shape":"hm","toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}